\section{相关工作和方法}

在利用大规模巡天数据搜寻如CEMP星等特殊恒星时，模板匹配法是一种被广泛应用的经典技术。其核心思想是通过将观测光谱与一个覆盖了广阔参数空间（$T_{\text{eff}}$, $\log g$, [Fe/H], [C/H]等）的参考光谱库进行比对，通过寻找最佳匹配来推断前者的物理参数。针对LAMOST巡天数据，该方法的具体实施包含以下三个关键环节：
\subsection{模板匹配法}
\subsubsection{参考光谱库的构建}
模板库的完备性与精度是决定该方法成败的基石。一个为CEMP星搜索优化的模板库需满足以下要求：
\begin{itemize}
    \item \textbf{理论光谱的生成：} 使用如MOOG等合成光谱代码，结合MARCS等先进的恒星大气模型，生成覆盖CEMP星典型参数范围的理论光谱。在生成过程中，必须精细考虑关键分子带（如CH G-band, C$_2$ Swan bands）的贡献，并模拟LAMOST的仪器展宽和星际消光效应。
    \item \textbf{参数空间的覆盖：} 模板库必须在$T_{\text{eff}}$ (4000-6500 K), $\log g$ (1.0-4.5 dex), [Fe/H] (-4.0 to 0.0 dex), 和 [C/Fe] (0.0 to +3.0 dex) 等维度上进行精细网格化采样，以确保对各类恒星都有精确的模板对应。
    \item \textbf{经验光谱的补充：} 为修正理论模型在极低金属丰度区域可能存在的系统偏差，通常会引入来自高分辨率观测（如SDSS/SEGUE, HET/HRS）的真实CEMP星光谱作为经验模板，以提升模板库的可靠性。
\end{itemize}

\subsubsection{光谱匹配与参数优化}
此环节的目标是在模板库中为每一条观测光谱找到最佳匹配。对于经过归一化等预处理的LAMOST低分辨率光谱，该过程通常通过$\chi^2$最小化来实现。具体而言，即求解一个非线性优化问题，其目标函数如下：
$
\min_{\theta, a, v_{\text{rad}}} \sum_{i} \left[ \frac{f_{\text{obs}}(\lambda_i) - a \cdot T(\lambda_i(1+v_{\text{rad}}/c); \theta)}{\sigma_i} \right]^2
$
其中，$f_{\text{obs}}$是观测流量，$T(\lambda; \theta)$是参数为$\theta$的模板光谱，$a$和$v_{\text{rad}}$分别是归一化尺度因子和视向速度，$\sigma_i$是噪声。此优化过程通常采用Levenberg-Marquardt等高效算法并行求解。参数的最终误差则常通过MCMC等贝叶斯方法进行估计。

\subsubsection{结果的后处理与验证}
为确保结果的可靠性，必须对初步匹配结果进行严格的后处理与验证：
\begin{itemize}
    \item \textbf{关键谱线检验：} 对所有候选体，计算关键的碳分子带（如CH G-band）的等值宽度或线指数，并设置信噪比阈值，以剔除因噪声导致的伪信号。
    \item \textbf{人工目视检查：} 对所有高置信度的候选体进行人工检查，以排除宇宙射线、光纤交叉污染等仪器效应的干扰。
    \item \textbf{外部交叉验证：} 将得到的结果与来自其他高分辨率巡天（如APOGEE）的参数测量结果进行比对，以评估系统误差和测量精度。
\end{itemize}

尽管模板匹配法在处理低信噪比数据时表现稳健，并能同时给出多个恒星参数，但其性能高度依赖于模板库的完备性，且在面对千万量级的巡天数据时，其计算成本高昂，难以满足自动化、高效率分析的需求。



随着LAMOST等大规模光谱巡天项目的深入，数据量呈爆炸式增长，传统的模板匹配法在效率和可扩展性上逐渐暴露瓶颈。与此同时，以支持向量机、随机森林为代表的传统机器学习方法，虽在一定程度上提升了自动化水平，但其性能高度依赖于人工设计的特征（如等值宽度、颜色指数等），在面对高维、非线性的光谱数据时，其建模能力和泛化性均受到限制。

近年来，数据驱动的深度学习方法为恒星光谱分析带来了范式上的革新。这类方法能够直接从原始光谱数据中自动学习层次化的特征表示，极大地降低了对特征工程的依赖，并在参数估计的精度和效率上取得了突破。在恒星参数估计领域，已有多种深度学习模型被成功应用：

\subsubsection{The Cannon: 数据驱动的光谱建模基石}
\label{subsec:cannon}
由Ness等人提出的\textbf{The Cannon} \cite{ness2015cannon}是该领域的里程碑式工作。它并非一个物理模型，而是一个数据驱动的生成模型。其核心思想是：在存在一个高精度“训练集”（即一组同时拥有光谱和精确参数的恒星）的前提下，可以学习到一个普适的函数，该函数将任意恒星的光谱流量与它的物理参数（“标签”）精确地联系起来。\textit{The Cannon}通常使用一个简单的多项式模型来拟合这种关系。在训练阶段，模型从参考样本中学习到光谱流量与恒星标签之间的映射关系；在应用阶段，对于只有光谱的未知天体，模型能够以极高的速度反解出其最可能的标签。该方法以其高效、稳健以及在低信噪比数据上的优异表现，被广泛应用于APOGEE等大型巡天项目中。

\subsubsection{SPCANet: 融合主成分分析的混合模型}
\textbf{SPCANet} \cite{wang2020spcanet}是一种结合了主成分分析（PCA）与深度神经网络（DNN）的混合模型。它首先利用PCA对高维光谱数据进行降维，提取出最主要的成分作为特征，此举能有效去除噪声并减少信息冗余。随后，这些低维特征被送入一个深度神经网络，通过非线性回归建模，学习从光谱主成分到恒星物理参数的复杂映射。SPCANet结合了PCA的线性和DNN的非线性建模能力，在处理低信噪比光谱时表现出很强的鲁棒性。

\subsubsection{SLAM: 端到端的卷积神经网络方法}
\textbf{SLAM (Stellar LAbel Machine)} \cite{zhang2020slam}是专为大规模光谱巡天设计的端到端深度学习模型。它采用卷积神经网络（CNN）架构，能够直接从原始的一维光谱像素中自动学习相关特征，无需任何人工干预。通过多层卷积与池化操作，SLAM能够有效捕捉光谱中的局部和全局结构信息（如吸收线的轮廓、相对强度等），并最终通过全连接层回归得到恒星参数。SLAM的端到端特性使其具备极高的自动化处理能力和对数据噪声、采样不均等问题的鲁棒性，是处理海量光谱数据的理想选择。

\subsubsection{SpecCLIP: 基于对比学习的光谱基础模型}近年来，天文学界开始借鉴自然语言处理和计算机视觉领域的成功经验，发展面向海量多模态数据的“基础模型”（Foundation Model）。\textbf{SpecCLIP} \cite{li2023, zhang2024} 正是这一趋势下的前沿代表，它将恒星光谱视为一种结构化的“语言”，旨在学习到一种能够泛化至多种下游任务的普适性光谱表示。SpecCLIP的核心思想源于强大的`CLIP` (Contrastive Language-Image Pre-training) 框架。它创新性地采用**对比学习**策略，将来自不同巡天项目、具有不同特征（如分辨率、波长覆盖）的光谱数据进行对齐。例如，将LAMOST的低分辨率光谱与Gaia BP/RP (XP)的光谱在同一个高维“嵌入空间”（Embedding Space）中进行匹配。其目标是让来自同一颗恒星的不同光谱在该空间中的表示尽可能接近，而来自不同恒星的光谱则相互远离。这种自监督的学习方式使得模型能够从海量的无标签数据中学习到光谱的内在物理结构。作为一个多模态模型，SpecCLIP能够自然地融合光谱信息与Gaia提供的高精度天体测量数据（如视差、自行）。这种跨模态学习带来了显著优势：一方面，精确的距离信息可以有效打破恒星参数（如$T_{\text{eff}}$和$\log g$）之间的简并性，从而大幅提升参数估计的精度；另一方面，统一的嵌入空间使得在不同巡天数据之间进行交叉定标和信息迁移成为可能。SpecCLIP的应用远不止于高精度的参数估计。其强大的表示学习能力使其在**异常光谱检测**、**相似天体搜寻**以及**跨模态光谱生成**（例如，从Gaia XP光谱预测LAMOST光谱）等任务中也展现出巨大潜力，为天文学研究提供了全新的探索工具。

\subsection{研究动机与方法革新}
\label{subsec:motivation_dl}

\textbf{下一代光谱巡天引发的数据挑战与科学机遇。}以LAMOST和SDSS-V为代表的光谱巡天项目，正将天文学带入一个前所未有的“太字节”(Petabyte)时代。其产生的数据量已逾千万量级，并仍在持续增长。这一数据的“洪流”为在银河系中系统性地搜寻像CEMP星这样的稀有天体提供了空前的机遇，但同时也对传统分析方法构成了严峻挑战。如前所述，经典的模板匹配法（第\ref{subsec:template_cemp}节）在这一新形势下面临着三个难以逾越的瓶颈：

\begin{itemize}
    \item \textbf{计算可扩展性瓶颈：} 模板匹配本质上是基于$\chi^2$最小化的网格搜索，其计算成本随参数空间维度（如考虑C, N, $\alpha$等多种元素丰度）呈指数级增长，无法满足海量数据的实时处理需求。
    \item \textbf{低信噪比下的稳健性问题：} 对于LAMOST产生的大量低信噪比（S/N < 15）光谱，关键的吸收线特征（如CH分子带）极易被噪声淹没，导致模板匹配法的参数测定，特别是碳丰度的误差急剧增大，可靠性降低。
    \item \textbf{模板库的不完备性与泛化难题：} 任何理论或经验模板库都难以完全覆盖所有可能的恒星参数，尤其是在极端物理区域（如[Fe/H] < -3.5或[C/Fe] > +2.0）。这使得模板匹配法在搜寻最稀有、最极端的CEMP星时，其探测效率和可靠性都受到根本性限制。
\end{itemize}

\textbf{深度学习：应对挑战的系统性解决方案。} 近年来，深度学习的迅猛发展为突破上述瓶颈提供了全新的、系统性的解决思路。它不再依赖于固定的模板库，而是直接从数据中学习光谱与物理参数之间的复杂映射关系。具体而言：

\begin{itemize}
    \item \textbf{应对可扩展性瓶颈：} 以卷积神经网络（CNN）为代表的端到端模型 \cite{ting2019}，能够直接从原始光谱像素中自动提取特征并进行回归，完全绕开了计算昂贵的网格搜索，处理速度相比传统方法可提升数个数量级。
    \item \textbf{应对低信噪比挑战：} CNN的层次化特征提取能力使其对噪声具有更强的鲁棒性。同时，贝叶斯神经网络等技术的发展 \cite{bayescnn2022}，使得模型在给出参数预测的同时，还能提供可靠的不确定性量化，这对于评估低信噪比数据的分析结果至关重要。
    \item \textbf{应对泛化能力难题：} 生成对抗网络（GAN）等生成式模型 \cite{zhang2021_gan}，能够学习真实光谱的数据分布，并据此生成海量的、物理真实的合成光谱，从而有效扩充和补完训练集在极端参数区域的覆盖，极大提升了模型在稀有天体搜寻任务中的泛化能力。
\end{itemize}

正是基于以上挑战与机遇，本研究旨在开发一种专为大规模巡天数据中的CEMP星高效搜寻而设计的新型深度学习框架。我们的方法将融合上述先进技术，以期在保证高精度的前提下，实现对海量光谱数据快速、稳健的自动化分析，从而为揭示银河系早期的化学演化历史提供一个前所未有的大样本。
